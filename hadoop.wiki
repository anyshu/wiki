= hadoop =

== hadoop_config ==
mtime: 2013-05-14 11:31:55 

=== 运行模式 ===
# 独立模式
# 伪分布模式
# 全分布模式
{{{
                            独立        伪分布              全分布
common  fs.default.name     file:///    hdfs://localhost/   hdfs://namenode/
HDFS    dfs.replication     N/A         1                   3
MapRecduce  mapred.job.tracker  local   localhost:8021      jobtracker:8021
}}}

* 格式化HDFS文件系统
hdfs namenode -format

创建hdfs目录,这一步,在hadoop安装配置完毕,必须进行,否则namenode无法启动.

* 启动/终止hdfs守护进程
start-dfs.sh

start-mapred.sh

XXX:
这里有一个顺序的问题,必须先通过format命令,初始化相应的hdfs,然后才可以start-dfs.sh,否则namenode总是启动不成功.(对应的路径没有name名称的路径)

* 可以通过hdfs getconf -namenodes等命令,来确认配置错误的具体地方,以及原因

== 全分布模式下 ==
=== hdfs ===

主节点运行namenode,secondarynamenode.

数据节点运行datanode

namenode,利用8020作为控制接入端口,50070是web查看端口.

secondarynamenode,占据50090端口.

datanode使用50010,50020,50075端口.

其中一般外部程序都是通过8020,与hdfs交互.

=== yarn ===
主节点运行resourcemanager

任务节点运行nodemanager

resourcemanager,利用8032作为rpc接入节点.8031作为其资源跟踪节点.8030作为其调度器端口.
8088是其web查看端口

nodemanager使用8040,与8042端口.

其中一般外部程序通过8032端口与yarn交互.

以上所有端口号都是默认配置,可以通过配置文件,确定其具体端口号是多少.

== 一般问题 ==
=== IPC version问题 ===

这是因为外部软件与hadoop的对应版本号不一致的问题.确保二者一致即可.或者编译外部软件指定明确对应的hadoop版本.

=== hdfs incompatible CID ===
这是因为namenode重新进行了格式化的操作,但是datanode上面,没有同步这方面的消息.这就导致datanode检查CID不一致,无法顺利启动.

修改只需要将datanode的对应文件夹删除即可.再次重新运行datanode就可以正常工作了.

== hdfs操作 ==
ref::[[http://hadoop.apache.org/docs/r0.19.0/hdfs_shell.html]]

基本通过命令hadoop fs命令完成.

- 格式化            hdfs namenode -format
- 从本地复制到hdfs  hadoop fs -copyFromLocal /path/name hdfs://localhost/path/name
    这里的hdfs://localhost/可以省略,因为这里已经在配置文件中做出了声明了.
- 从hdfs复制到本地  hadoop fs -copyToLocal filename localfile
- ls命令            hadoop fs -ls pathname
    其中第二列的是备份个数
- 创建目录          hadoop fs -mkdir pathname

注意到hadoop有一个抽象文件系统概念.其中hdfs仅仅是实现其接口的其中一种文件系统.

而本地文件系统,以及其他文件系统,也可以对接到hadoop上来.

- put
复制本地文件系统中的,单个文件或者多个文件到目的文件系统.也可以从标准输入到目的文件系统(使用-表示)
