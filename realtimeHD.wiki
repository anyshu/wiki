= readtimeHD =
== local method of Stereo Vision ==
立体视觉的本地方法

ref:计算机视觉算法与应用 11.4 局部方法

通过在DSI C(x,y,d)上的一个支持区域求取代价和或者平均值来聚集代价的.

一个支持区域,可以是固定视差上的二维区域(对正向平行表面很有用),也可以是x-y-d空间上的三维区域(支持倾斜表面).

`我们要处理倾斜表面(人脸),而且表面的三维结构还较明显`

二维的聚集方式包含下面:
* 平方窗口
* 高斯卷积,固定在不同点的多窗口(可移动)
* 基于常量视差的连通域的出口
* 基于彩色分割

对于三维支持窗口:
* 受限视差
* 受限视差梯度
* 一致性准则
* 等等.

_C(x,y,d) = w(x,y,d) * C0(x,y,d)_


= review of RealTimeHD =
2012 ACM IVCNZ

== Abstract ==
在很多应用中,速度与精度是立体视觉中最为重要的两个方面.很少有作者同时关注这两个方面.

在本篇论文中,我们提出新的本地算法,实时的速度下得到高精度.

我们的GPU实现,可以达到4839 MDE/s(每秒百万次距离估计),目前的最快速度.同时保有最好的精度.

算法获得高精度,依赖于匹配决策中的稳定的标准.

一个定量和定性的估计,在middleburry的评估中,对我们的执行速度和匹配精度都做了测试.

获得如此的性能,对于3D多媒体和娱乐开启了新的路径.

== 介绍 ==

传统方法依赖于对应点匹配,而这是一个病态问题.很多东西,都会对这个产生影响(...)

最近的全局方法,如图切法,信念传播方法,规避了这些问题,可以得到较高的精度,但是计算量很大.
事实上,全局方法的计算量过大,以至于无法用于实时应用.

而本地方法,则易于计算,适合加速.但是本地方法,一般都对于前面提到的问题比较敏感.距离图中的噪声点很多.
而且本地方法还有发胖现象(是的对象边界膨胀).

这样似乎就只可以在高精度和速度之间选择一个了.这里我们的结果表示不是这样的.

`介绍就像一个童话故事啊,一个恶龙把公主抓走了,大家都没有办法.这个时候王子出现了!!!`


*精度限制的块匹配算法,使用GPU对其加速.*


该方法有`[25] How accurate can block matches be in stereo vision?`提出.但是没有达到实时.

有很多方法,对此进行了类似讨论.一些使用[[dynamic_programming]]算法和分层信念传播方法达到了实时效果.

但是我们的方法在相同的精度下,速度可以是它的70倍.

有一个利用FPGA和GPU的快速动态规划算法.但是没有提到它达到的精度水平.无法进行比较.

另外[16]分析了5种不同的对应点匹配算法.并且分析了其速度和质量上的优势,以及极限.

动态规划算法和本地块匹配算法是达到令人注目的速度的两大方法.后者相对没有那么耀眼,如果考虑到质量的话.
至少很明显的,本地方法距离要达到实际应用需要的精度还有一段距离.


最精确的本地方法基于 *自适应窗口* .例如[31]Yoon & Kweon,提出了对于窗口内的像素根据距离中心的距离和颜色差异决定其支持权重.`也就是双边方方法`.
尽管有较好的计算结果,但是速度非常之慢.使得算法完全不可能应用与实时应用.
几位作者受到算法的激励,提出了基于自适应窗口的实时方法.
例如[24],使用高斯权重的双向双边方法.
[8],提出的简化的,但是快速,精确度稍降的方法.
[10],提出的二进制窗口方法
[12],指导滤波方法.
除了上边的,[8],还研究了不同的ACF对于处理速度和匹配质量的影响.

为了获得最好的执行时间,很多作者利用立体方法的固有并行特性,在GPU上实现了他们的算法.[30,29].
还有些作者,是哦那个了GPU的CUDA.[12,20,5,24].

_作者没有直接说自己基于那个方法,这个怎么办?_


== 匹配算法 ==

=== 稳定标准 ===
边缘保留的平滑滤波器,关键的改进在于不像是其他的,忽视匹配质量而令所有的像素点的权重是一样的.

在闭塞或者无纹理的区域,...

有一些方法来估计匹配的可信度.很多依赖于ACF.例如[22]中,就使用了最小值的相对宽度.(这种方法使得我们的实现的速度减慢).

[19],定义了匹配误差函数,第一个到第二最小值的相对强度.

但是更好的[21],提出使用3个最小值.

如果ACF是一个亚像素最小值,那么两个值的稳定肯定没有3个的那么稳定.

[21]定义了C=M3/M1.

我们定义了C=(M3-M1)/M3.

这样就有w=C*exp(-(D0+D1+D2)).

== 算法的快速实现 ==
本地算法,非常适合与GPU计算.

_计算每个像素点的匹配距离,都可以作为GPU硬件的一个线程运行._

基本的GPU优化,这里就不再讨论了.

# 主机到设备内存的异步传输.
# 使用快速存储类型
# 合并需求??
# 纹理化数据用于缓存
# 边界切分
# 纹理插值
# 使用Nvidia FERMI架构的SFU.

下面是算法中用到的加速方法:
=== 多层金字塔的本地搜索 ===
=== 选择合适的ACF ===
零均值的ACF,需要计算窗口内的均值.这样就需要两次的扫描过程?

另一方面,归一化的ACF,则不是GPU设备资源的威胁.因为寄存器的个数,可以直接对应到并行执行的线程个数.

因此我们使用SSD,而不是ZSSD,或者NCC(归一化的).

事实上,SSD快速而且极端鲁棒.因为左右图像的预滤波是非常快的.
=== 计算ACF ===
传统的方式为线程到像素的映射过程.

这里我们.不是如此,而是将图像划分为M*N的p块.使用的内核总数等于p.

每个块使用N个线程来计算,每个线程处理滑动窗口的一列??(不是一行???),这样总需要的线程个数为p*N个.

ACF计算,半宽度?n*m.每个行的计算?

TODO:

=== 滑动窗口 ===

=== 1D 滤波 ===

== 本方法的快速之处 ==
# ACF计算简单
其实很多时候的计算过程,都会花费在这一部分.
# local方法适合于并行化
虽然动态规划算法也可以减少很多计算量,但是却不方便进行并行化处理,因为其依赖于之前的计算结果.
# 金字塔方法加速
金字塔的过程,则加快的算法的处理速度以及精度.很多时候,就可以利用这个特性.而且可以快速达到比较高的精度,如1/4像素.


----
= adaptive Support-Weight Approach for Correspondence Search =
自适应支持权重的对应点搜索

2006 Yoon & Kweon. PAMI.

== abstract ==
提出一个使用可变支持权证的基于窗口的对应点搜索.

...

== 介绍 ==

_对应点搜索方法_ 的症结是图像的歧义性,因为本地的像素点可以是图像噪声,或者无效的纹理.
当图像像素的本地结构相似的时候,很难进行全局的搜索,...

自适应窗口法,则对每个像素点寻找光学上最优的窗口大小.`最后一点的灵感好像大家都已经探索过了的了`
{{{
深度越小的,则所需要的窗口越小,深度越大的,则所需要的窗口越大.
深度越小的,则立体匹配的距离差别就越大,深度越大的,则立体匹配的距离就越小.
}}}
`使用本文的双边方法的好处,就是不需要再进行这种费力而不讨好的估计`

== 人视觉系统中的支持聚合 ==
只有当像素点为相同深度的时候,(有着相同的视差),邻点的支持才是有效的.

然而,并不知道像素点的时差距离(这个正是我们要求的).这样[1],[10],[12]采用迭代的方式,更新支持窗口,或者支持权重.
`迭代的思路是很明显的,但是计算的复杂度,显然会比较麻烦`
这个迭代的过程对于初始的距离估计又是非常敏感的.`不是一个良性的搜索问题`.
为了解决这个问题,我们观察了人的视觉系统.事实上在支持窗口内,不同的像素点的重要性是不同的.

=== 格式塔组 ===
=== 基于格式塔的支持权重 ===

== 本地自适应支持权证计算 ==
=== 相似组的强度 ===
CIElab颜色空间中,像素颜色的区分,提供了对于颜色刺激感觉的三维表示.
CIElab颜色空间中,两点距离越大,两个颜色给出的感觉越是不同.
特别的,较小的欧式距离,当Delta C(pq)表示二者的距离,那么两个颜色的感知差异为:

D(cp,cq) = 1 - exp(- Delta[C(p,q)]/gamma)

gamma=14.

基于上式,颜色相似组的强度,定义如下:

fs(Delta[C(p,q)]) = exp(-Delta/gamma(c)). `gamma(c),表示颜色的gamma值.`

=== 接近分组的强度 ===
这里的定义是类似的,根据接近的格式塔原色,一个像素的支持权重,随着距离参考像素的距离而递减.

只有较小的空间距离下,人的区分是相关的.因此定义如下laplacian的核如下.

fp(Delta[G(p,q)]) = exp(-Delta/gamma(p)).

这里gamma(p)正比于窗口大小.

=== 基于分组强度的支持权重 ===
...

w(p,q) = ...

这里注意的是,不依赖于初始估计,因为自适应支持权重的计算是完全基于给定窗口的上下文信息.

== 相似度的计算和距离选取 ==

dissimilarity(也就是匹配消耗),两个像素间的,通过计算两个的支持窗口下的支持权重.这一步,不像以前的方法,我们考虑了引用和目标支持窗口的支持权重.
计算dissimilarity,可能是错的.当目标支持窗口的像素,来自与不同的深度的时候.
为了最小化这样的像素点的影响,dissimilarity两点间的,都组合了两个支持窗口的权重.为了组合权重,二者的dissimilarity如下:

E(p,pd) = sum[ w(p,q)w(pd,qd)e(q,qd) ]/sum[w(p,q)w(pd,qd)]

这里pd和qd是目标图像的对应点.而p,q是引用图像上距离为d.

e(q,qd),表示基于表素的直接匹配(对于q和qd).这里使用的是绝对差值.

e(q,qd) = min (sum |Ic(q) - Ic(qd)|,T)

Ic是颜色c的强度, T是控制匹配消耗极限的舍去值.??

dissimilarity计算之后,每个像素点的距离计算可以按照WTA(赢者通吃)原则.

dp = args min E(p,pd)


----
----

= 实现的流程 =

# 去光照
# CIElab变换
# ACF:SSD计算
# 金字塔方法(中指滤波)
# 递归1D-三边滤波
# 动态规划

算法流程:
# 全局预处理
    # 去光照
    # CIElab变换
# 本地匹配过程`本地匹配过程,是否需要动态规划,还是直接强行搜索??`
    # 
# 可靠性估计`可靠性估计如何发挥作用`

`首先利用Matlab实现算法的模型,然后再考虑通过CUDA/OpenCL实现.`

TODO:
需要一份最基本的关于本地算法的介绍的资料??


THINK:
深度越小的,则所需要的窗口越小,深度越大的,则所需要的窗口越大.
深度越小的,则立体匹配的距离差别就越大,深度越大的,则立体匹配的距离就越小.

这里使用立体视觉的方法,进行抗姿态的匹配,一个关键问题,就是立体视觉经常使用的共极线的默认约束,在抗姿态人脸匹配过程中其实是不太合理的.
这也就是其算法,在PIE数据集上边,有些摄像头的位置下的图像是根本不能进行计算的原因.

